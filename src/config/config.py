from dotenv import load_dotenv
import os

load_dotenv(override=False)

# Rest API server configuration
SERVER_HOST = os.getenv("SERVER_HOST", "127.0.0.1")
SERVER_PORT = int(os.getenv("SERVER_PORT", "6060"))
LOG_LEVEL = os.getenv("LOG_LEVEL", "info")
MAX_CACHE_SIZE = int(os.getenv("MAX_CACHE_SIZE", "16384"))
MAX_CACHE_TTL = int(os.getenv("MAX_CACHE_TTL", "3600"))

# Model inference configuration
MODEL_PATH = os.getenv("MODEL_PATH")

USE_LLAMA_CPP = os.getenv("USE_LLAMA_CPP", "false").lower() == 'true'
LLAMA_CPP_MAX_CONTEXT = int(os.getenv("LLAMA_CPP_MAX_CONTEXT", "2048"))
LLAMA_CPP_BATCH_TOKENS = int(os.getenv("LLAMA_CPP_BATCH_TOKENS", "2048"))
LLAMA_RAM_CACHE_MB = int(os.getenv("LLAMA_RAM_CACHE_MB", "512"))

ENABLE_CUDA = os.getenv("ENABLE_CUDA", "true").lower() == 'true'
DEVICE_MAP_AUTO = os.getenv("DEVICE_MAP_AUTO", "true").lower() == 'true'
TARGET_GPU_INDEX = int(os.getenv("TARGET_GPU_INDEX", "0"))
LOAD_IN_8BIT = os.getenv("LOAD_IN_8BIT", "False").lower() == 'true'
LOAD_IN_4BIT = os.getenv("LOAD_IN_4BIT", "False").lower() == 'true'
SPACE_TOKEN_CHAR = os.getenv("SPACE_TOKEN_CHAR")

# Token generation configuration
MODEL_SEED = int(os.getenv("MODEL_SEED", "42"))
MODEL_LOADER = os.getenv("MODEL_LOADER", "AutoModelForCausalLM")
MODEL_DEFAULT_NUM_BEAMS = int(os.getenv("MODEL_DEFAULT_NUM_BEAMS", "1"))
MODEL_DEFAULT_DO_SAMPLE = os.getenv("MODEL_DEFAULT_DO_SAMPLE", "True").lower() == 'true'
MODEL_DEFAULT_TEMPERATURE = float(os.getenv("MODEL_DEFAULT_TEMPERATURE", "1"))
MODEL_DEFAULT_TOP_P = float(os.getenv("MODEL_DEFAULT_TOP_P", "1"))
MODEL_DEFAULT_TOP_K = int(os.getenv("MODEL_DEFAULT_TOP_K", "50"))

# Token generation penalties and limitations
MODEL_DEFAULT_MAX_NEW_TOKENS = int(os.getenv("MODEL_DEFAULT_MAX_NEW_TOKENS", "4096"))
MODEL_DEFAULT_REPETITION_PENALTY = float(os.getenv("MODEL_DEFAULT_REPETITION_PENALTY", "1"))
MODEL_DEFAULT_LENGTH_PENALTY = float(os.getenv("MODEL_DEFAULT_LENGTH_PENALTY", "1"))

BASE_MODEL_CONFIG = {
    "ENABLE_CUDA": ENABLE_CUDA,
    "DEVICE_MAP_AUTO": DEVICE_MAP_AUTO,
    "LOAD_IN_8BIT": LOAD_IN_8BIT,
    "LOAD_IN_4BIT": LOAD_IN_4BIT,
    "SPACE_TOKEN_CHAR": SPACE_TOKEN_CHAR,
    "TARGET_GPU_INDEX": TARGET_GPU_INDEX,
    "MODEL_SEED": MODEL_SEED,
    "MODEL_LOADER": MODEL_LOADER,
    "MODEL_DEFAULT_NUM_BEAMS": MODEL_DEFAULT_NUM_BEAMS,
    "MODEL_DEFAULT_DO_SAMPLE": MODEL_DEFAULT_DO_SAMPLE,
    "MODEL_DEFAULT_TEMPERATURE": MODEL_DEFAULT_TEMPERATURE,
    "MODEL_DEFAULT_TOP_P": MODEL_DEFAULT_TOP_P,
    "MODEL_DEFAULT_TOP_K": MODEL_DEFAULT_TOP_K,
    "MODEL_DEFAULT_MAX_NEW_TOKENS": MODEL_DEFAULT_MAX_NEW_TOKENS,
    "MODEL_DEFAULT_REPETITION_PENALTY": MODEL_DEFAULT_REPETITION_PENALTY,
    "MODEL_DEFAULT_LENGTH_PENALTY": MODEL_DEFAULT_LENGTH_PENALTY,
}
